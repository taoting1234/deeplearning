{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_epochs = 3\n",
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "learning_rate = 0.01\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\code\\python\\deeplearning\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = keras.datasets.mnist.load_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data)) \\\n",
    "    .map(lambda a, b: (tf.reshape(a, (28, 28, 1)) / 255, tf.one_hot(b, 10))) \\\n",
    "    .shuffle(1000).repeat(train_epochs).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_data, y_test_data)) \\\n",
    "    .map(lambda a, b: (tf.reshape(a, (28, 28, 1)) / 255, tf.one_hot(b, 10))) \\\n",
    "    .shuffle(1000).repeat().batch(test_batch_size)\n",
    "\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "train_next_element = train_iterator.get_next()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_next_element = test_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1], name='x')\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-59457bbadb2c>:2: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-59457bbadb2c>:3: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-59457bbadb2c>:7: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-59457bbadb2c>:8: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=x, filters=32, kernel_size=[5, 5], strides=1, padding='same',\n",
    "                         activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[5, 5], strides=1, padding='same', activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "dense = tf.layers.dense(inputs=flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "pred = tf.layers.dense(inputs=dropout, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\code\\python\\deeplearning\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "loss_function = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(pred, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_iterator.initializer)\n",
    "sess.run(test_iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:10 loss:2.19492 acc:0.39000\n",
      "step:20 loss:0.89070 acc:0.77000\n",
      "step:30 loss:0.70179 acc:0.82000\n",
      "step:40 loss:0.45469 acc:0.87000\n",
      "step:50 loss:0.33685 acc:0.89000\n",
      "step:60 loss:0.21600 acc:0.91000\n",
      "step:70 loss:0.10503 acc:0.96000\n",
      "step:80 loss:0.31802 acc:0.87000\n",
      "step:90 loss:0.29480 acc:0.91000\n",
      "step:100 loss:0.15414 acc:0.94000\n",
      "step:110 loss:0.14932 acc:0.96000\n",
      "step:120 loss:0.37373 acc:0.88000\n",
      "step:130 loss:0.19650 acc:0.96000\n",
      "step:140 loss:0.31090 acc:0.93000\n",
      "step:150 loss:0.06920 acc:0.98000\n",
      "step:160 loss:0.12032 acc:0.96000\n",
      "step:170 loss:0.11968 acc:0.96000\n",
      "step:180 loss:0.08314 acc:0.98000\n",
      "step:190 loss:0.11174 acc:0.94000\n",
      "step:200 loss:0.40000 acc:0.91000\n",
      "step:210 loss:0.08295 acc:0.98000\n",
      "step:220 loss:0.11841 acc:0.95000\n",
      "step:230 loss:0.19886 acc:0.95000\n",
      "step:240 loss:0.24587 acc:0.94000\n",
      "step:250 loss:0.11570 acc:0.97000\n",
      "step:260 loss:0.08717 acc:0.97000\n",
      "step:270 loss:0.11507 acc:0.96000\n",
      "step:280 loss:0.14027 acc:0.93000\n",
      "step:290 loss:0.06835 acc:0.96000\n",
      "step:300 loss:0.06158 acc:0.98000\n",
      "step:310 loss:0.19100 acc:0.95000\n",
      "step:320 loss:0.06524 acc:0.98000\n",
      "step:330 loss:0.16664 acc:0.95000\n",
      "step:340 loss:0.09798 acc:0.96000\n",
      "step:350 loss:0.10804 acc:0.96000\n",
      "step:360 loss:0.15583 acc:0.94000\n",
      "step:370 loss:0.07509 acc:0.97000\n",
      "step:380 loss:0.07275 acc:0.97000\n",
      "step:390 loss:0.02412 acc:1.00000\n",
      "step:400 loss:0.11941 acc:0.97000\n",
      "step:410 loss:0.09631 acc:0.94000\n",
      "step:420 loss:0.10585 acc:0.97000\n",
      "step:430 loss:0.05387 acc:0.99000\n",
      "step:440 loss:0.05830 acc:0.98000\n",
      "step:450 loss:0.01030 acc:1.00000\n",
      "step:460 loss:0.02147 acc:1.00000\n",
      "step:470 loss:0.10209 acc:0.97000\n",
      "step:480 loss:0.06137 acc:0.99000\n",
      "step:490 loss:0.02689 acc:1.00000\n",
      "step:500 loss:0.06533 acc:0.98000\n",
      "step:510 loss:0.05903 acc:0.99000\n",
      "step:520 loss:0.10600 acc:0.97000\n",
      "step:530 loss:0.05126 acc:0.97000\n",
      "step:540 loss:0.01771 acc:0.99000\n",
      "step:550 loss:0.00106 acc:1.00000\n",
      "step:560 loss:0.00827 acc:1.00000\n",
      "step:570 loss:0.13046 acc:0.95000\n",
      "step:580 loss:0.01060 acc:1.00000\n",
      "step:590 loss:0.08214 acc:0.97000\n",
      "step:600 loss:0.03258 acc:0.99000\n",
      "step:610 loss:0.09887 acc:0.97000\n",
      "step:620 loss:0.03735 acc:0.99000\n",
      "step:630 loss:0.05921 acc:0.97000\n",
      "step:640 loss:0.05955 acc:0.99000\n",
      "step:650 loss:0.04750 acc:0.99000\n",
      "step:660 loss:0.04817 acc:0.98000\n",
      "step:670 loss:0.06742 acc:0.98000\n",
      "step:680 loss:0.08822 acc:0.97000\n",
      "step:690 loss:0.06601 acc:0.99000\n",
      "step:700 loss:0.02782 acc:0.99000\n",
      "step:710 loss:0.01557 acc:1.00000\n",
      "step:720 loss:0.06047 acc:0.97000\n",
      "step:730 loss:0.15612 acc:0.98000\n",
      "step:740 loss:0.01197 acc:0.99000\n",
      "step:750 loss:0.00621 acc:1.00000\n",
      "step:760 loss:0.10633 acc:0.96000\n",
      "step:770 loss:0.00304 acc:1.00000\n",
      "step:780 loss:0.02404 acc:0.99000\n",
      "step:790 loss:0.04000 acc:0.99000\n",
      "step:800 loss:0.06484 acc:0.97000\n",
      "step:810 loss:0.01385 acc:0.99000\n",
      "step:820 loss:0.00420 acc:1.00000\n",
      "step:830 loss:0.03228 acc:0.99000\n",
      "step:840 loss:0.00822 acc:1.00000\n",
      "step:850 loss:0.03051 acc:0.97000\n",
      "step:860 loss:0.00223 acc:1.00000\n",
      "step:870 loss:0.00181 acc:1.00000\n",
      "step:880 loss:0.13851 acc:0.95000\n",
      "step:890 loss:0.04295 acc:0.98000\n",
      "step:900 loss:0.03091 acc:0.99000\n",
      "step:910 loss:0.04833 acc:0.98000\n",
      "step:920 loss:0.09230 acc:0.98000\n",
      "step:930 loss:0.09827 acc:0.97000\n",
      "step:940 loss:0.06825 acc:0.97000\n",
      "step:950 loss:0.05663 acc:0.99000\n",
      "step:960 loss:0.15478 acc:0.96000\n",
      "step:970 loss:0.09196 acc:0.97000\n",
      "step:980 loss:0.02704 acc:0.99000\n",
      "step:990 loss:0.07332 acc:0.98000\n",
      "step:1000 loss:0.13910 acc:0.95000\n",
      "step:1010 loss:0.06365 acc:0.97000\n",
      "step:1020 loss:0.09840 acc:0.97000\n",
      "step:1030 loss:0.31780 acc:0.92000\n",
      "step:1040 loss:0.11812 acc:0.97000\n",
      "step:1050 loss:0.10503 acc:0.96000\n",
      "step:1060 loss:0.11189 acc:0.96000\n",
      "step:1070 loss:0.05554 acc:0.98000\n",
      "step:1080 loss:0.01666 acc:1.00000\n",
      "step:1090 loss:0.09491 acc:0.96000\n",
      "step:1100 loss:0.06405 acc:0.98000\n",
      "step:1110 loss:0.15344 acc:0.95000\n",
      "step:1120 loss:0.15244 acc:0.96000\n",
      "step:1130 loss:0.05717 acc:0.99000\n",
      "step:1140 loss:0.14266 acc:0.94000\n",
      "step:1150 loss:0.11374 acc:0.97000\n",
      "step:1160 loss:0.25208 acc:0.92000\n",
      "step:1170 loss:0.01891 acc:0.99000\n",
      "step:1180 loss:0.19289 acc:0.93000\n",
      "step:1190 loss:0.05697 acc:0.97000\n",
      "step:1200 loss:0.16558 acc:0.94000\n",
      "step:1210 loss:0.18363 acc:0.96000\n",
      "step:1220 loss:0.12097 acc:0.99000\n",
      "step:1230 loss:0.12626 acc:0.96000\n",
      "step:1240 loss:0.05567 acc:0.98000\n",
      "step:1250 loss:0.09202 acc:0.97000\n",
      "step:1260 loss:0.10827 acc:0.96000\n",
      "step:1270 loss:0.04643 acc:0.99000\n",
      "step:1280 loss:0.04597 acc:0.98000\n",
      "step:1290 loss:0.06875 acc:0.97000\n",
      "step:1300 loss:0.13119 acc:0.96000\n",
      "step:1310 loss:0.11446 acc:0.97000\n",
      "step:1320 loss:0.14603 acc:0.96000\n",
      "step:1330 loss:0.03978 acc:0.98000\n",
      "step:1340 loss:0.13827 acc:0.93000\n",
      "step:1350 loss:0.07970 acc:0.95000\n",
      "step:1360 loss:0.04172 acc:0.98000\n",
      "step:1370 loss:0.14351 acc:0.95000\n",
      "step:1380 loss:0.05477 acc:0.98000\n",
      "step:1390 loss:0.06332 acc:0.97000\n",
      "step:1400 loss:0.04707 acc:0.97000\n",
      "step:1410 loss:0.04699 acc:0.99000\n",
      "step:1420 loss:0.19550 acc:0.96000\n",
      "step:1430 loss:0.02997 acc:0.99000\n",
      "step:1440 loss:0.05923 acc:0.99000\n",
      "step:1450 loss:0.02156 acc:0.99000\n",
      "step:1460 loss:0.01741 acc:0.99000\n",
      "step:1470 loss:0.11139 acc:0.97000\n",
      "step:1480 loss:0.03534 acc:0.99000\n",
      "step:1490 loss:0.04226 acc:0.99000\n",
      "step:1500 loss:0.04607 acc:0.98000\n",
      "step:1510 loss:0.05029 acc:0.99000\n",
      "step:1520 loss:0.01320 acc:1.00000\n",
      "step:1530 loss:0.02849 acc:0.99000\n",
      "step:1540 loss:0.06089 acc:0.98000\n",
      "step:1550 loss:0.00674 acc:1.00000\n",
      "step:1560 loss:0.12124 acc:0.98000\n",
      "step:1570 loss:0.10485 acc:0.96000\n",
      "step:1580 loss:0.06509 acc:0.98000\n",
      "step:1590 loss:0.00776 acc:1.00000\n",
      "step:1600 loss:0.03917 acc:0.98000\n",
      "step:1610 loss:0.04087 acc:0.98000\n",
      "step:1620 loss:0.01444 acc:1.00000\n",
      "step:1630 loss:0.03682 acc:0.98000\n",
      "step:1640 loss:0.06694 acc:0.98000\n",
      "step:1650 loss:0.13312 acc:0.98000\n",
      "step:1660 loss:0.02149 acc:0.99000\n",
      "step:1670 loss:0.01616 acc:0.99000\n",
      "step:1680 loss:0.04637 acc:0.98000\n",
      "step:1690 loss:0.04945 acc:0.99000\n",
      "step:1700 loss:0.13803 acc:0.98000\n",
      "step:1710 loss:0.02500 acc:0.99000\n",
      "step:1720 loss:0.00532 acc:1.00000\n",
      "step:1730 loss:0.07795 acc:0.99000\n",
      "step:1740 loss:0.01128 acc:0.99000\n",
      "step:1750 loss:0.04487 acc:0.98000\n",
      "step:1760 loss:0.03316 acc:0.99000\n",
      "step:1770 loss:0.03254 acc:0.99000\n",
      "step:1780 loss:0.10179 acc:0.96000\n",
      "step:1790 loss:0.01013 acc:1.00000\n",
      "step:1800 loss:0.01331 acc:0.99000\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "while 1:\n",
    "    try:\n",
    "        xs, ys = sess.run(train_next_element)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "\n",
    "    sess.run([optimizer], feed_dict={x: xs, y: ys})\n",
    "    step += 1\n",
    "    if step % display_step == 0:\n",
    "        xss, yss = sess.run(test_next_element)\n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict={x: xss, y: yss})\n",
    "        print('step:{:d} loss:{:.05f} acc:{:.05f}'.format(step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推测的数字 [0 2 5 5 2 9 7 0 4 1 4 2 9 2 0 9 6 1 3 1]\n",
      "真实的数字 [0 2 5 5 2 9 7 0 4 1 4 2 9 2 0 9 6 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "xss, yss = sess.run(test_next_element)\n",
    "pred_y = np.argmax(sess.run(pred, {x: xss[:20]}), 1)\n",
    "true_y = np.argmax(yss[:20], 1)\n",
    "print('推测的数字', pred_y)\n",
    "print('真实的数字', true_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
